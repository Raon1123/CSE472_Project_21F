{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "#from train_model import train_step, test_step\n",
    "from models.decisiontree import DecisionTree\n",
    "from utils.load_data import get_data\n",
    "from utils.make_dict import train_bow, get_bow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "args ={'dataset': 'cifar10',\n",
    "       'dataroot': './data',\n",
    "       'model': 'custom_SVM',\n",
    "       'kernel': 'gaussian',\n",
    "       'validation': 0.1,\n",
    "       'C': 5.0,\n",
    "       'sigma': 1.0,\n",
    "       'batch': 1000,\n",
    "       'dict_size': 100,\n",
    "       'train': True,\n",
    "       'load_cluster': True\n",
    "       }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ntrainX, trainy = get_data(dataset=args[\\'dataset\\'], train=True, dataroot=args[\\'dataroot\\'])\\ntrainX = trainX.reshape((-1, 32, 32, 3), order=\\'F\\')\\n\\nif args[\\'load_cluster\\']:\\n    with open(\"./cluster.dump\", \"rb\") as f:\\n        cluster = pickle.load(f)\\nelse:\\n    cluster = train_bow(trainX, num_dict=args[\\'dict_size\\'], num_select=10000)\\n    with open(\"./cluster.dump\", \"wb\") as f:\\n        pickle.dump(cluster, f)\\n\\ntrainFeature = get_bow(trainX, cluster, num_dict=args[\\'dict_size\\'])\\n'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "trainX, trainy = get_data(dataset=args['dataset'], train=True, dataroot=args['dataroot'])\n",
    "trainX = trainX.reshape((-1, 32, 32, 3), order='F')\n",
    "\n",
    "if args['load_cluster']:\n",
    "    with open(\"./cluster.dump\", \"rb\") as f:\n",
    "        cluster = pickle.load(f)\n",
    "else:\n",
    "    cluster = train_bow(trainX, num_dict=args['dict_size'], num_select=10000)\n",
    "    with open(\"./cluster.dump\", \"wb\") as f:\n",
    "        pickle.dump(cluster, f)\n",
    "\n",
    "trainFeature = get_bow(trainX, cluster, num_dict=args['dict_size'])\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, trainy = get_data(dataset=args['dataset'], train=True, dataroot=args['dataroot'])\n",
    "with open(\"./feature.dump\", \"rb\") as f:\n",
    "    trainFeature = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DecisionTree()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\MLV\\OneDrive - UNIST\\UNIST\\2021_Fall\\CSE472_컴퓨터비전\\Vision_Framework\\models\\decisiontree.py:53: RuntimeWarning: divide by zero encountered in log2\n",
      "  neg_entropy = -1.0 * prob * np.log2(prob)\n",
      "c:\\Users\\MLV\\OneDrive - UNIST\\UNIST\\2021_Fall\\CSE472_컴퓨터비전\\Vision_Framework\\models\\decisiontree.py:53: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  neg_entropy = -1.0 * prob * np.log2(prob)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<models.decisiontree.DecisionTree at 0x1a3c83adb48>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(trainFeature, trainy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12.767999999999999\n"
     ]
    }
   ],
   "source": [
    "y = model.predict(trainFeature)\n",
    "boolean = (y == trainy)\n",
    "print(np.sum(boolean) / trainy.shape[0] * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./cluster.dump\", \"rb\") as f:\n",
    "    cluster = pickle.load(f)\n",
    "testX, testy = get_data(dataset=args['dataset'], train=False, dataroot=args['dataroot'])\n",
    "testX = testX.reshape((-1, 32, 32, 3), order='F')\n",
    "testFeature = get_bow(testX, cluster, num_dict=args['dict_size'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model.predict(testFeature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., ..., 0., 0., 6.])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "boolean = (pred == testy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11.690000000000001\n"
     ]
    }
   ],
   "source": [
    "print(np.sum(boolean) / testy.shape[0] * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "e12f6ab8f072a3343ec40e7c2da6d7bef24e88ada4fc34ffff4c29dc2d68ce9e"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
