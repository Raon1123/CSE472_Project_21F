{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "#from train_model import train_step, test_step\n",
    "from models.decisiontree import DecisionTree, RandForest\n",
    "from utils.load_data import get_data\n",
    "from utils.make_dict import train_bow, get_bow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "args ={'dataset': 'cifar10',\n",
    "       'dataroot': './data',\n",
    "       'model': 'custom_SVM',\n",
    "       'kernel': 'gaussian',\n",
    "       'validation': 0.1,\n",
    "       'C': 5.0,\n",
    "       'sigma': 1.0,\n",
    "       'batch': 1000,\n",
    "       'dict_size': 100,\n",
    "       'train': True,\n",
    "       'load_cluster': True\n",
    "       }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ntrainX, trainy = get_data(dataset=args[\\'dataset\\'], train=True, dataroot=args[\\'dataroot\\'])\\ntrainX = trainX.reshape((-1, 32, 32, 3), order=\\'F\\')\\n\\nif args[\\'load_cluster\\']:\\n    with open(\"./cluster.dump\", \"rb\") as f:\\n        cluster = pickle.load(f)\\nelse:\\n    cluster = train_bow(trainX, num_dict=args[\\'dict_size\\'], num_select=10000)\\n    with open(\"./cluster.dump\", \"wb\") as f:\\n        pickle.dump(cluster, f)\\n\\ntrainFeature = get_bow(trainX, cluster, num_dict=args[\\'dict_size\\'])\\n'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "trainX, trainy = get_data(dataset=args['dataset'], train=True, dataroot=args['dataroot'])\n",
    "trainX = trainX.reshape((-1, 32, 32, 3), order='F')\n",
    "\n",
    "if args['load_cluster']:\n",
    "    with open(\"./cluster.dump\", \"rb\") as f:\n",
    "        cluster = pickle.load(f)\n",
    "else:\n",
    "    cluster = train_bow(trainX, num_dict=args['dict_size'], num_select=10000)\n",
    "    with open(\"./cluster.dump\", \"wb\") as f:\n",
    "        pickle.dump(cluster, f)\n",
    "\n",
    "trainFeature = get_bow(trainX, cluster, num_dict=args['dict_size'])\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, trainy = get_data(dataset=args['dataset'], train=True, dataroot=args['dataroot'])\n",
    "with open(\"./feature.dump\", \"rb\") as f:\n",
    "    trainFeature = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RandForest(forest=10, bag_size=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [04:46<00:00, 28.69s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<models.decisiontree.RandForest at 0x1c62a8ead48>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(trainFeature, trainy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12.988\n"
     ]
    }
   ],
   "source": [
    "y = model.predict(trainFeature)\n",
    "boolean = (y == trainy)\n",
    "print(np.sum(boolean) / trainy.shape[0] * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./cluster.dump\", \"rb\") as f:\n",
    "    cluster = pickle.load(f)\n",
    "testX, testy = get_data(dataset=args['dataset'], train=False, dataroot=args['dataroot'])\n",
    "if args['dataset'] == 'cifar10':\n",
    "    testX = testX.reshape((-1, 32, 32, 3), order='F')\n",
    "testFeature = get_bow(testX, cluster, num_dict=args['dict_size'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model.predict(testFeature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 1., 1., ..., 1., 1., 1.])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "boolean = (pred == testy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14.2\n"
     ]
    }
   ],
   "source": [
    "print(np.sum(boolean) / testy.shape[0] * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "e12f6ab8f072a3343ec40e7c2da6d7bef24e88ada4fc34ffff4c29dc2d68ce9e"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
