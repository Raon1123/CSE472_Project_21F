{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "#from train_model import train_step, test_step\n",
    "from models.decisiontree import DecisionTree, RandForest\n",
    "from utils.load_data import get_data\n",
    "from utils.make_dict import train_bow, get_bow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "args ={'dataset': 'cifar10',\n",
    "       'dataroot': './data',\n",
    "       'model': 'custom_SVM',\n",
    "       'kernel': 'gaussian',\n",
    "       'validation': 0.1,\n",
    "       'dict_size': 300,\n",
    "       'load_cluster': False\n",
    "       }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainX, trainy = get_data(dataset=args['dataset'], train=True, dataroot=args['dataroot'])\n",
    "if args['dataset'] == 'cifar10':\n",
    "    trainX = trainX.reshape((-1, 32, 32, 3), order='F')\n",
    "\n",
    "if args['load_cluster']:\n",
    "    with open(\"./cluster.dump\", \"rb\") as f:\n",
    "        cluster = pickle.load(f)\n",
    "else:\n",
    "    cluster = train_bow(trainX, num_dict=args['dict_size'], num_select=10000)\n",
    "    with open(\"./cluster.dump\", \"wb\") as f:\n",
    "        pickle.dump(cluster, f)\n",
    "\n",
    "trainFeature = get_bow(trainX, cluster, num_dict=args['dict_size'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RandForest(forest=10, bag_size=5000, depth=100)\n",
    "#model = DecisionTree(depth=150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(trainFeature, trainy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction, pred = model.predict(trainFeature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainFeature.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boolean = (pred == trainy)\n",
    "print(np.sum(boolean) / trainy.shape[0] * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./cluster.dump\", \"rb\") as f:\n",
    "    cluster = pickle.load(f)\n",
    "testX, testy = get_data(dataset=args['dataset'], train=False, dataroot=args['dataroot'])\n",
    "if args['dataset'] == 'cifar10':\n",
    "    testX = testX.reshape((-1, 32, 32, 3), order='F')\n",
    "testFeature = get_bow(testX, cluster, num_dict=args['dict_size'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model.predict(testFeature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boolean = (pred[1] == testy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.sum(boolean) / testy.shape[0] * 100)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "e12f6ab8f072a3343ec40e7c2da6d7bef24e88ada4fc34ffff4c29dc2d68ce9e"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
